{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 4, 1836, 128])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# 假设张量已经定义\n",
    "k_states_reloaded = torch.rand(1, 4, 1620, 128)\n",
    "k_activation_part1 = torch.rand(1, 4, 14, 128)\n",
    "k_activation_part2 = torch.rand(1, 4, 202, 128)\n",
    "\n",
    "# 按指定顺序在 dim=2 上拼接\n",
    "result = torch.cat((k_activation_part1, k_states_reloaded, k_activation_part2), dim=2)\n",
    "\n",
    "# 检查拼接后的形状\n",
    "print(result.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Manual time: 0.1141 seconds\n",
      "SPA time: 0.1138 seconds\n",
      "Speedup: 1.00×\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import time\n",
    "\n",
    "# 测试参数\n",
    "batch_size, seq_len, embed_dim = 16, 2512, 4096  # 修改序列长度和维度测试\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "query = torch.randn(batch_size, seq_len, embed_dim, device=device)\n",
    "key = torch.randn(batch_size, seq_len, embed_dim, device=device)\n",
    "value = torch.randn(batch_size, seq_len, embed_dim, device=device)\n",
    "attn_mask = torch.ones(seq_len, seq_len, dtype=torch.bool, device=device).tril()\n",
    "\n",
    "# 手动实现\n",
    "def manual_scaled_dot_product_attention(query, key, value, attn_mask=None):\n",
    "    scale_factor = 1 / query.size(-1) ** 0.5\n",
    "    attn_weights = query @ key.transpose(-2, -1) * scale_factor\n",
    "    if attn_mask is not None:\n",
    "        attn_weights = attn_weights.masked_fill(attn_mask.logical_not(), float(\"-inf\"))\n",
    "    attn_weights = torch.softmax(attn_weights, dim=-1)\n",
    "    return attn_weights @ value\n",
    "\n",
    "# 测试时间\n",
    "def benchmark(func, *args):\n",
    "    torch.cuda.synchronize()\n",
    "    start = time.time()\n",
    "    func(*args)\n",
    "    torch.cuda.synchronize()\n",
    "    return time.time() - start\n",
    "\n",
    "# 手动实现时间\n",
    "manual_time = benchmark(manual_scaled_dot_product_attention, query, key, value, attn_mask)\n",
    "print(f\"Manual time: {manual_time:.4f} seconds\")\n",
    "\n",
    "# PyTorch SPA 时间\n",
    "spa_time = benchmark(\n",
    "    torch.nn.functional.scaled_dot_product_attention,\n",
    "    query, key, value, attn_mask\n",
    ")\n",
    "print(f\"SPA time: {spa_time:.4f} seconds\")\n",
    "\n",
    "# 计算加速比\n",
    "print(f\"Speedup: {manual_time / spa_time:.2f}×\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "attn_logits: tensor([[[[4.6599e-01, 9.3160e-01, 6.0031e-01,  ..., 8.3951e-01,\n",
      "           3.9051e-01, 3.6991e-01],\n",
      "          [9.1105e-01, 9.6870e-01, 1.9888e-01,  ..., 4.7841e-01,\n",
      "           7.0689e-01, 8.2734e-01],\n",
      "          [9.7203e-01, 9.3085e-03, 9.1803e-01,  ..., 2.8146e-01,\n",
      "           9.7307e-01, 3.3683e-01],\n",
      "          ...,\n",
      "          [5.2449e-01, 1.8395e-01, 5.4980e-01,  ..., 8.5767e-01,\n",
      "           6.9943e-01, 6.4617e-01],\n",
      "          [9.8120e-01, 1.6080e-01, 2.5963e-01,  ..., 9.2691e-01,\n",
      "           6.9573e-01, 3.1241e-01],\n",
      "          [6.1523e-01, 6.5969e-01, 1.0094e-01,  ..., 7.5538e-01,\n",
      "           2.7946e-01, 3.8473e-01]],\n",
      "\n",
      "         [[7.6536e-01, 7.7824e-01, 9.7660e-01,  ..., 3.1278e-01,\n",
      "           8.5102e-01, 6.7716e-01],\n",
      "          [2.7048e-01, 9.2083e-01, 7.0344e-01,  ..., 4.6432e-01,\n",
      "           9.5548e-01, 3.5643e-01],\n",
      "          [1.9052e-01, 5.7030e-04, 1.8468e-01,  ..., 4.0759e-01,\n",
      "           2.8387e-01, 8.3967e-01],\n",
      "          ...,\n",
      "          [2.6715e-01, 6.0837e-01, 1.7380e-01,  ..., 7.5837e-01,\n",
      "           8.3690e-01, 2.6270e-01],\n",
      "          [7.5718e-01, 4.0960e-01, 7.0927e-01,  ..., 2.5763e-01,\n",
      "           4.4599e-01, 3.3705e-01],\n",
      "          [8.3780e-01, 5.4923e-01, 7.6644e-01,  ..., 7.5603e-01,\n",
      "           4.1615e-01, 4.6168e-01]],\n",
      "\n",
      "         [[6.7349e-01, 4.6011e-01, 9.2576e-01,  ..., 5.4766e-01,\n",
      "           5.7688e-01, 4.7215e-01],\n",
      "          [5.3197e-01, 7.1947e-01, 4.8491e-01,  ..., 6.5988e-01,\n",
      "           8.4697e-01, 6.6417e-01],\n",
      "          [8.2016e-01, 1.8357e-01, 1.7224e-01,  ..., 7.9001e-01,\n",
      "           6.4811e-01, 4.7643e-01],\n",
      "          ...,\n",
      "          [7.0428e-01, 1.9708e-02, 7.2172e-01,  ..., 4.4912e-01,\n",
      "           1.3725e-01, 5.2789e-01],\n",
      "          [9.5310e-02, 8.1339e-01, 6.8308e-01,  ..., 7.4423e-01,\n",
      "           5.7126e-01, 4.0963e-01],\n",
      "          [1.6652e-01, 3.9561e-01, 7.8495e-01,  ..., 4.7816e-01,\n",
      "           1.7362e-01, 8.2219e-01]],\n",
      "\n",
      "         [[8.3661e-01, 4.4723e-01, 5.6277e-01,  ..., 2.2211e-01,\n",
      "           3.7308e-01, 4.9832e-01],\n",
      "          [3.7979e-01, 9.7520e-01, 5.6582e-01,  ..., 2.0353e-01,\n",
      "           4.6597e-01, 2.5564e-01],\n",
      "          [2.4566e-01, 9.5702e-02, 8.1480e-01,  ..., 6.8446e-01,\n",
      "           5.1729e-01, 6.1735e-01],\n",
      "          ...,\n",
      "          [4.2872e-01, 6.1033e-01, 4.2128e-01,  ..., 8.5102e-02,\n",
      "           5.9014e-01, 9.0026e-01],\n",
      "          [4.0122e-01, 6.7629e-01, 4.7055e-01,  ..., 6.1367e-01,\n",
      "           7.2978e-02, 2.6920e-01],\n",
      "          [3.7914e-01, 5.0324e-01, 2.8067e-01,  ..., 8.4814e-01,\n",
      "           5.2997e-01, 8.7146e-01]]]])\n",
      "attn_logits.shape : torch.Size([1, 4, 8, 256])\n",
      "attn_logits_sum: tensor([[[5.3878, 3.4414, 3.7243,  ..., 4.8040, 5.0029, 3.8261],\n",
      "         [3.9129, 4.1403, 4.3558,  ..., 3.6453, 4.8748, 3.4401],\n",
      "         [4.1470, 3.3869, 4.8223,  ..., 4.2896, 3.9555, 4.4164],\n",
      "         [3.5087, 5.0071, 4.5518,  ..., 3.9364, 3.3814, 4.6220]]])\n",
      "attn_logits_sum.shape : torch.Size([1, 4, 256])\n",
      "attn_logits_avg: tensor([[4.2391, 3.9939, 4.3635, 4.6239, 4.1085, 4.3551, 4.7615, 4.2004, 3.7103,\n",
      "         3.5851, 4.1461, 4.0848, 4.1943, 3.2004, 3.5973, 3.6051, 4.6042, 4.2325,\n",
      "         4.0031, 3.2835, 3.7934, 4.9160, 3.9232, 4.2643, 4.1189, 3.5006, 4.3708,\n",
      "         3.5920, 3.8668, 3.3987, 4.0458, 4.5349, 4.6499, 3.6664, 4.3675, 4.4152,\n",
      "         3.5462, 4.0417, 4.7242, 4.3813, 4.5648, 3.9348, 3.6871, 4.0213, 4.2576,\n",
      "         3.8841, 3.8689, 4.2734, 4.4105, 3.9751, 3.5345, 3.6416, 3.4467, 4.5476,\n",
      "         3.7876, 4.5260, 3.9246, 4.2104, 4.1557, 4.3803, 3.3654, 4.4999, 4.3449,\n",
      "         3.3782, 3.9868, 4.0316, 4.6788, 3.6136, 3.9569, 3.7281, 3.9195, 4.0359,\n",
      "         3.3360, 4.0146, 4.3826, 3.1910, 4.0901, 3.2408, 3.9200, 4.1907, 4.7354,\n",
      "         4.3052, 4.4291, 4.3633, 3.9128, 3.2575, 3.9880, 4.5825, 4.0147, 4.8796,\n",
      "         3.6935, 3.9732, 3.8464, 3.4304, 4.1449, 4.0310, 4.0483, 3.1528, 4.1583,\n",
      "         4.5332, 3.8038, 3.8951, 4.1578, 3.8443, 4.7847, 4.4581, 3.7536, 4.0314,\n",
      "         3.6363, 4.1591, 4.5047, 4.6318, 3.4136, 4.6346, 3.5034, 4.4980, 3.5403,\n",
      "         4.0166, 4.1499, 3.9443, 3.7046, 4.7666, 4.1784, 4.2358, 4.1003, 4.5604,\n",
      "         3.5253, 4.1740, 4.0969, 4.3518, 2.9407, 4.0476, 3.3919, 3.4228, 4.1969,\n",
      "         3.5886, 4.3142, 4.3682, 4.4059, 3.6981, 3.2174, 3.7585, 3.6402, 3.2566,\n",
      "         4.0336, 4.7796, 3.4125, 4.2982, 4.5784, 3.5761, 4.1674, 3.7437, 3.6251,\n",
      "         4.1325, 3.7235, 3.9040, 3.5696, 4.1875, 4.0768, 4.1565, 4.1771, 4.3381,\n",
      "         4.3175, 3.8672, 4.1490, 3.6434, 4.3900, 3.7514, 3.9479, 4.2431, 4.0959,\n",
      "         4.3766, 3.7363, 3.4984, 4.1741, 4.4272, 3.6597, 4.2156, 3.3198, 3.8062,\n",
      "         3.2052, 4.1480, 3.9844, 4.1193, 4.1499, 3.9445, 3.4328, 4.2009, 3.6609,\n",
      "         4.5569, 3.8369, 4.3123, 3.8003, 4.1777, 3.9987, 3.2723, 4.0707, 3.8794,\n",
      "         3.9572, 3.8375, 3.9603, 4.1540, 4.1239, 3.6821, 3.6651, 3.6188, 3.6433,\n",
      "         3.5387, 4.7336, 4.1765, 4.4867, 4.4432, 4.3343, 4.2766, 4.2026, 3.3942,\n",
      "         4.0124, 4.0447, 3.9712, 3.2221, 3.7850, 4.6853, 3.7534, 4.3109, 4.0144,\n",
      "         4.0695, 3.7831, 3.6302, 3.9408, 4.3861, 3.7641, 3.5501, 3.9472, 4.2657,\n",
      "         4.5099, 3.7517, 4.2489, 4.8369, 4.3867, 4.2331, 4.2827, 3.4516, 3.9198,\n",
      "         3.9209, 3.9368, 3.4973, 3.6630, 3.7983, 3.0338, 4.0146, 3.7012, 3.8629,\n",
      "         4.1181, 4.1688, 4.3036, 4.0762]])\n",
      "attn_logits_avg.shape : torch.Size([1, 256])\n",
      "batch.shape: torch.Size([256])\n",
      "start: 16, end: 32\n",
      "start: 64, end: 128\n",
      "start: 129, end: 139\n",
      "start: 200, end: 210\n",
      "batch_chunk_avg: tensor([[4.0280, 4.0376, 3.9028, 3.9296]])\n",
      "batch_chunk_avg.shape: torch.Size([1, 4])\n"
     ]
    }
   ],
   "source": [
    "def scaled_dot_product_attention_for_reload_step2(attn_logits, chunk_infos, top_k=3):\n",
    "    # 将每个视觉token对于文本token的attention进行求和\n",
    "    print(f'attn_logits: {attn_logits}')\n",
    "    print(f'attn_logits.shape : {attn_logits.shape}')\n",
    "    attn_logits_sum = attn_logits.sum(dim=-2) # (batch_size, nheads, seqlen)\n",
    "    print(f'attn_logits_sum: {attn_logits_sum}')\n",
    "    print(f'attn_logits_sum.shape : {attn_logits_sum.shape}')\n",
    "    attn_logits_avg = attn_logits_sum.mean(dim=1) # 将每个 head 求平均 (batch_size, seqlen)\n",
    "    print(f'attn_logits_avg: {attn_logits_avg}')\n",
    "    print(f'attn_logits_avg.shape : {attn_logits_avg.shape}')\n",
    "\n",
    "    batch_chunk_avg = []\n",
    "\n",
    "    # 对 batch 维度逐一处理\n",
    "    for batch in attn_logits_avg:\n",
    "        # 保存当前 batch 的 chunk 平均值\n",
    "        chunk_avg = []\n",
    "        print(f'batch.shape: {batch.shape}')\n",
    "        for chunk_idx, start, end in chunk_infos:\n",
    "            print(f'start: {start}, end: {end}')\n",
    "            # 对当前 chunk 的元素取均值\n",
    "            chunk_score = batch[start: end].mean()  \n",
    "            chunk_avg.append(chunk_score)\n",
    "        batch_chunk_avg.append(chunk_avg)\n",
    "\n",
    "    # 转换为张量，形状为 (batch_size, n_chunks)\n",
    "    batch_chunk_avg = torch.tensor(batch_chunk_avg)\n",
    "    print(f'batch_chunk_avg: {batch_chunk_avg}')\n",
    "    print(f'batch_chunk_avg.shape: {batch_chunk_avg.shape}')\n",
    "\n",
    "    # chunk_infos 的数量 小于 k，全部纳入\n",
    "    if batch_chunk_avg.shape[-1] < top_k:\n",
    "        topk_values = batch_chunk_avg\n",
    "        topk_indices = torch.arange(batch_chunk_avg.shape[-1])\n",
    "        return topk_values, topk_indices\n",
    "\n",
    "    topk_values, topk_indices = torch.topk(batch_chunk_avg, k=top_k, dim=1)\n",
    "    return topk_values, topk_indices[0]\n",
    "\n",
    "import torch\n",
    "\n",
    "attn_logits = torch.rand(1,4,8,256)\n",
    "chunk_infos = [(1, 16,32),(2, 64,128), (3, 129,139),(4,200, 210)]\n",
    "\n",
    "topk_values, topk_indices = scaled_dot_product_attention_for_reload_step2(attn_logits, chunk_infos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "随机选中的 chunk: 1\n",
      "(2, 64, 128)\n",
      "随机选中的 chunk: 0\n",
      "(1, 16, 32)\n",
      "随机选中的 chunk: 3\n",
      "(4, 200, 210)\n"
     ]
    }
   ],
   "source": [
    "for indice in topk_indices:\n",
    "    chunk_idx_selected = indice \n",
    "    print(f'随机选中的 chunk: {chunk_idx_selected}')\n",
    "    chunk_info = chunk_infos[chunk_idx_selected]\n",
    "    print(chunk_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 3, 0]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topk_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[ True,  True,  True, False, False, False],\n",
       "          [ True,  True,  True,  True, False, False],\n",
       "          [ True,  True,  True,  True,  True, False],\n",
       "          [ True,  True,  True,  True,  True,  True]]]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "tgt_size = 4\n",
    "mem_size = 2\n",
    "batch_size = 1\n",
    "src_size = 6\n",
    "causal_mask = torch.full((tgt_size, tgt_size), False, dtype=torch.bool)\n",
    "\n",
    "mask_cond = torch.arange(causal_mask.size(-1))\n",
    "causal_mask.masked_fill_(mask_cond < (mask_cond + 1).view(causal_mask.size(-1), -1), True)\n",
    "\n",
    "causal_mask = torch.cat([torch.ones(tgt_size, mem_size, dtype=torch.bool), causal_mask], dim=-1)\n",
    "\n",
    "causal_mask = causal_mask[None, None, ...].expand(batch_size, 1, tgt_size, src_size)\n",
    "causal_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-28 10:30:59.981\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m12\u001b[0m - \u001b[1mThis is an INFO message\u001b[0m\n",
      "\u001b[32m2024-11-28 10:30:59.982\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m13\u001b[0m - \u001b[31m\u001b[1mThis is an ERROR message\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from loguru import logger as eval_logger\n",
    "import sys\n",
    "\n",
    "# 清空默认的 logger 配置\n",
    "eval_logger.remove()\n",
    "\n",
    "# 添加一个新的 handler，指定输出到控制台，级别为 INFO\n",
    "eval_logger.add(sys.stderr, level=\"INFO\")\n",
    "\n",
    "# 测试日志\n",
    "eval_logger.debug(\"This is a DEBUG message\")  # 不会显示\n",
    "eval_logger.info(\"This is an INFO message\")   # 会显示\n",
    "eval_logger.error(\"This is an ERROR message\")  # 会显示\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<loguru.logger handlers=[(id=5, level=20, sink='stderr')]>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[True, True, True, True],\n",
       "          [True, True, True, True],\n",
       "          [True, True, True, True],\n",
       "          [True, True, True, True]],\n",
       "\n",
       "         [[True, True, True, True],\n",
       "          [True, True, True, True],\n",
       "          [True, True, True, True],\n",
       "          [True, True, True, True]],\n",
       "\n",
       "         [[True, True, True, True],\n",
       "          [True, True, True, True],\n",
       "          [True, True, True, True],\n",
       "          [True, True, True, True]]]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "# L = 4\n",
    "# S = 8\n",
    "# res = torch.zeros(1,1,L, S, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "\n",
    "attn_mask = torch.zeros((1,3,2,4),dtype=torch.bool)\n",
    "attn_bias = torch.zeros(attn_mask.shape, dtype=torch.float32)\n",
    "attn_bias = attn_bias.to(attn_mask.device)\n",
    "\n",
    "\n",
    "if attn_mask is not None:\n",
    "    if attn_mask.dtype == torch.bool:\n",
    "        attn_bias.masked_fill_(attn_mask.logical_not(), float(\"-inf\"))\n",
    "    else:\n",
    "        attn_bias += attn_mask\n",
    "# attn_weight = query @ key.transpose(-2, -1) * scale_factor\n",
    "    \n",
    "# attn_weight += attn_bias.to(query.device)\n",
    "# attn_weight = torch.softmax(attn_weight, dim=-1)\n",
    "# attn_logits = attn_weight\n",
    "attn_bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-14464.], dtype=torch.float16)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "test = [-14464.6035]\n",
    "\n",
    "torch.tensor(test, dtype=torch.float16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 2]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "effective_chunk_infos = [1,2,3]\n",
    "\n",
    "bsz = 2\n",
    "\n",
    "range(len(effective_chunk_infos))\n",
    "\n",
    "topk_indices = random.sample(range(len(effective_chunk_infos)), 2)\n",
    "topk_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27]'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str(list(range(0,28)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27]\n",
    "\n",
    "if layer_idx not in [0, 1, 2, 14, 15, 16, 25, 26, 27]:\n",
    "    continue\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
